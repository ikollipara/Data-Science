import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
plt.style.use("ggplot")
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import explained_variance_score, mean_squared_error, make_scorer, confusion_matrix, classification_report
from sklearn.linear_model import Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier
from sklearn.preprocessing import StandardScaler


df = pd.read_csv("WhiteWine.csv", sep=";")


sns.histplot(df, x="quality", discrete=True)
plt.title("Distribution of Quality Ratings")


print("Pearson (Linear)")
print(df.corrwith(df["quality"]).sort_values())
print()
print("Spearman Rank (Monotonic)")
df.corrwith(df["quality"], method="spearman").sort_values()


scaler = StandardScaler()
X = scaler.fit_transform(df[["density", "chlorides", "volatile acidity"]])
y = df["quality"]
X_train, X_test, y_train, y_test = train_test_split(X, y)


get_ipython().run_cell_magic("time", "", """
param_grid = {"alpha": [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 1.5, 2]}

rg = GridSearchCV(Ridge(), param_grid, n_jobs=-1).fit(X_train, y_train)

print("Best Score")
print(rg.best_score_)
print()
print("Best Parameters")
print(rg.best_params_)
print()
rg_model = rg.best_estimator_""")


get_ipython().run_cell_magic("time", "", """
y_pred = rg_model.predict(X_test)

print(f"Explained Variance Score: {explained_variance_score(y_test, y_pred)}")
print(f"Mean Squared Error:       {mean_squared_error(y_test, y_pred)}")
print()""")


get_ipython().run_cell_magic("time", "", """
param_grid = {
    "criterion": ["squared_error", "absolute_error"],
    "min_samples_split": [2, 4, 6],
    "max_features": [None, "auto", "log2", "sqrt"],
}

dtg = GridSearchCV(DecisionTreeRegressor(), param_grid, n_jobs=-1).fit(X_train, y_train)

print("Best Score")
print(dtg.best_score_)
print()
print("Best Parameters")
print(dtg.best_params_)
print()
dtg_model = dtg.best_estimator_""")


get_ipython().run_cell_magic("time", "", """
y_pred = dtg_model.predict(X_test)

print(f"Explained Variance Score: {explained_variance_score(y_test, y_pred)}")
print(f"Mean Squared Error:       {mean_squared_error(y_test, y_pred)}")
print()""")


get_ipython().run_cell_magic("time", "", """
X = df.drop(columns=["quality"])
y = df["quality"]

X_train, X_test, y_train, y_test = train_test_split(X, y)

param_grid = {
    "criterion": ["entropy", "gini"],
    "max_features": ["log2", "sqrt", None],
    "min_samples_split": [1, 2],
    "min_samples_split": [2, 4, 6, 8, 10]
}

dt_grid = GridSearchCV(DecisionTreeClassifier(), param_grid, n_jobs=-1).fit(X_train, y_train)

print("Best Score")
print(dt_grid.best_score_)
print()
print("Best Params")
print(dt_grid.best_params_)
print()
model = dt_grid.best_estimator_""")


y_pred = model.predict(X_test)
print("Confusion Matrix")
print(confusion_matrix(y_test, y_pred))
print()
print("Classification Report")
print(classification_report(y_test, y_pred))
