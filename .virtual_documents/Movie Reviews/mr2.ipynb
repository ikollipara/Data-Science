import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
plt.style.use("ggplot")
import nltk
nltk.download("wordnet")
from nltk.stem import WordNetLemmatizer
from wordcloud import WordCloud

from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix


df = pd.read_csv("movie.csv")
print(df.shape)
df.head(5)


df['length'] = df['text'].map(lambda text: len(text))


values = df["label"].value_counts().values
plt.figure(figsize=(8, 6))
sns.barplot(x=["Negative", "Positive"], y=values, alpha=0.9)

plt.title("Distribution of Positive vs. Negative Reviews")
plt.ylabel("Count")
plt.xlabel("Classification")


df.groupby("label").count()


df.groupby("label")["length"].describe()


threshold = 2300
df[df["length"] < threshold].hist("length", by="label", bins=500, figsize=(12, 6))


plt.figure(figsize=(8, 6))
sns.stripplot(y="length", x="label", data=df[df["length"] > threshold])
plt.title("Comparison of long length reviews and their classification")
plt.xlabel("Classification")
df[df["length"] > threshold].groupby("label").count()


print(df[df["length"] > threshold].corr())
print()
print(df[df["length"] > threshold].corr("spearman"))


lemmatizer = WordNetLemmatizer()
