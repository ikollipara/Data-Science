import re
import numpy as np
import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
plt.style.use("ggplot")
import nltk
nltk.download("wordnet")
nltk.download("punkt")
nltk.download("omw-1.4")
from nltk.stem import WordNetLemmatizer, LancasterStemmer
from wordcloud import WordCloud

from sklearn.experimental import enable_halving_search_cv
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.pipeline import Pipeline
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, make_scorer
from sklearn.feature_extraction.text import CountVectorizer
from sklearn.naive_bayes import BernoulliNB, MultinomialNB
from sklearn.model_selection import HalvingGridSearchCV, GridSearchCV, train_test_split, cross_val_score


df = pd.read_csv("movie.csv")
print(df.shape)
df.head(5)


df["length"] = df["text"].map(lambda text: len(text))
df.head(5)


values = df["label"].value_counts().values
plt.figure(figsize=(8, 6))
sns.barplot(x=["Negative", "Positive"], y=values, alpha=0.9)

plt.title("Distribution of Positive vs. Negative Reviews")
plt.ylabel("Count")
plt.xlabel("Classification")
df.groupby("label").count()


df.groupby("label")["length"].describe()


t = 2300
df[df["length"] < t].hist("length", by="label", bins=500, figsize=(12, 6))


plt.figure(figsize=(8, 6))
sns.stripplot(y="length", x="label", data=df[df["length"] > t])
plt.title("Comparison of long length reviews and their classification")
plt.xlabel("Classification")
df[df["length"] > t].groupby("label").count()


df[df["length"] > t].corr()


X = df['text']
y = df['label']


get_ipython().run_cell_magic("time", "", """
lemmatizer = WordNetLemmatizer()

def lemmatize(text: str) -> str:
    lemmatized_review = (lemmatizer.lemmatize(w.lower()) for w in nltk.wordpunct_tokenize(text))
    return " ".join(lemmatized_review)

X_lemmatized = X.map(lambda text: lemmatize(text))""")


get_ipython().run_cell_magic("time", "", """
stemmer = LancasterStemmer()

def stem(text: str) -> str:
    stemmed_review = (stemmer.stem(w.lower()) for w in nltk.wordpunct_tokenize(text))
    return " ".join(stemmed_review)

X_stemmed = X.map(lambda text: stem(text))""")


get_ipython().run_cell_magic("time", "", """
with open("stop-words.txt") as f:
    stop_words_lemmatized = [lemmatizer.lemmatize(w.strip("\n")) for w in f]

def filter_by_stop_words(text: str) -> str:
    review = []
    for word in nltk.wordpunct_tokenize(text):
        if word not in stop_words_lemmatized:
            review.append(word)
    return " ".join(review)
        
X_lemmatized = X_lemmatized.map(lambda text: filter_by_stop_words(text))""")


get_ipython().run_cell_magic("time", "", """
with open("stop-words.txt") as f:
    stop_words_stemmed = [stemmer.stem(w.strip("\n")) for w in f]
    
def filter_by_stop_words(text: str) -> str:
    review = []
    for word in nltk.wordpunct_tokenize(text):
        if word not in stop_words_stemmed:
            review.append(word)
    return " ".join(review)

X_stemmed = X_stemmed.map(lambda text: filter_by_stop_words(text))""")


print("Original:")
print(df["text"][171])
print()
print("Lemmatization:")
print(X_lemmatized[171])
print()
print("Stemmed:")
print(X_stemmed[171])


lemmatized_word_cloud = (WordCloud(width=3000, 
                                  height=2000, 
                                  background_color='salmon', 
                                  colormap='Pastel1', 
                                  collocations=False, 
                                  random_state=1)
                         .generate(X_lemmatized[171]))

plt.figure(figsize=(40, 30))
plt.imshow(lemmatized_word_cloud)
plt.axis("off")


stemmed_word_cloud = (WordCloud(width=3000, 
                                  height=2000, 
                                  background_color='salmon', 
                                  colormap='Pastel1', 
                                  collocations=False, 
                                  random_state=1)
                         .generate(X_stemmed[171]))

plt.figure(figsize=(40, 30))
plt.imshow(stemmed_word_cloud)
plt.axis("off")


get_ipython().run_cell_magic("time", "", """
binary_vector = CountVectorizer(ngram_range=(1, 2), binary=True)
count_vector = CountVectorizer(ngram_range=(1, 2))

Xb_stemmed = binary_vector.fit_transform(X_stemmed)
Xc_stemmed = count_vector.fit_transform(X_stemmed)

Xb_lemmatized = binary_vector.fit_transform(X_lemmatized)
Xc_lemmatized = count_vector.fit_transform(X_lemmatized)""")


Xbs_train, Xbs_test, ybs_train, ybs_test = train_test_split(Xb_stemmed, y)
Xcs_train, Xcs_test, ycs_train, ycs_test = train_test_split(Xc_stemmed, y)

Xbl_train, Xbl_test, ybl_train, ybl_test = train_test_split(Xb_lemmatized, y)
Xcl_train, Xcl_test, ycl_train, ycl_test = train_test_split(Xc_lemmatized, y)


get_ipython().run_cell_magic("time", "", """
param_grid = {"alpha": [0.001, 0.01, 0.1, 0.2, 0.5, 1, 1.5, 2]}

bernoulli_grid = GridSearchCV(BernoulliNB(), param_grid, n_jobs=-1).fit(Xbs_train, ybs_train)

print("Binary")
print(f"Best Score: {bernoulli_grid.best_score_}") 
print(f"Optimal Values: {bernoulli_grid.best_params_}") 

bernoulli_grid = GridSearchCV(BernoulliNB(), param_grid, n_jobs=-1).fit(Xcs_train, ycs_train)

print("Count")
print(f"Best Score: {bernoulli_grid.best_score_}") 
print(f"Optimal Values: {bernoulli_grid.best_params_}") """)


get_ipython().run_cell_magic("time", "", """
param_grid = {"alpha": [0.001, 0.01, 0.1, 0.2, 0.5, 1, 1.5, 2]}

bernoulli_grid = GridSearchCV(BernoulliNB(), param_grid, n_jobs=-1).fit(Xbl_train, ybl_train)

print("Binary")
print(f"Best Score: {bernoulli_grid.best_score_}") 
print(f"Optimal Values: {bernoulli_grid.best_params_}") 

bernoulli_grid = GridSearchCV(BernoulliNB(), param_grid, n_jobs=-1).fit(Xcl_train, ycl_train)

print("Count")
print(f"Best Score: {bernoulli_grid.best_score_}") 
print(f"Optimal Values: {bernoulli_grid.best_params_}") """)


get_ipython().run_cell_magic("time", "", """
ideal_bernoulli = BernoulliNB(alpha=0.2).fit(Xbs_train, ybs_train)

ys_pred = ideal_bernoulli.predict(Xbs_test)

print("Confusion Matrix")
print(confusion_matrix(ybs_test, ys_pred))
print()
print(classification_report(ybs_test, ys_pred))
print()""")


get_ipython().run_cell_magic("time", "", """
ideal_bernoulli = BernoulliNB(alpha=0.2).fit(Xbl_train, ybl_train)

yl_pred = ideal_bernoulli.predict(Xbl_test)

print("Confusion Matrix")
print(confusion_matrix(ybl_test, yl_pred))
print()
print(classification_report(ybl_test, yl_pred))
print()""")


get_ipython().run_cell_magic("time", "", """
param_grid = {"alpha": [0.001, 0.01, 0.1, 0.2, 0.5, 1, 1.5, 2]}

multinomial_grid = GridSearchCV(MultinomialNB(), param_grid, n_jobs=-1).fit(Xbs_train, ybs_train)

print("Binary")
print(f"Best Score: {multinomial_grid.best_score_}") 
print(f"Optimal Values: {multinomial_grid.best_params_}") 

multinomial_grid = GridSearchCV(MultinomialNB(), param_grid, n_jobs=-1).fit(Xcs_train, ycs_train)

print("Count")
print(f"Best Score: {multinomial_grid.best_score_}") 
print(f"Optimal Values: {multinomial_grid.best_params_}") """)


get_ipython().run_cell_magic("time", "", """
param_grid = {"alpha": [0.001, 0.01, 0.1, 0.2, 0.5, 1, 1.5, 2]}

multinomial_grid = GridSearchCV(MultinomialNB(), param_grid, n_jobs=-1).fit(Xbl_train, ybl_train)

print("Binary")
print(f"Best Score: {multinomial_grid.best_score_}") 
print(f"Optimal Values: {multinomial_grid.best_params_}") 

multinomial_grid = GridSearchCV(MultinomialNB(), param_grid, n_jobs=-1).fit(Xcl_train, ycl_train)

print("Count")
print(f"Best Score: {multinomial_grid.best_score_}") 
print(f"Optimal Values: {multinomial_grid.best_params_}") """)


get_ipython().run_cell_magic("time", "", """
ideal_multinomial = MultinomialNB(alpha=2).fit(Xbs_train, ybs_train)

ys_pred = ideal_multinomial.predict(Xbs_test)

print("Confusion Matrix")
print(confusion_matrix(ybs_test, ys_pred))
print()
print(classification_report(ybs_test, ys_pred))
print()""")


get_ipython().run_cell_magic("time", "", """
ideal_multinomial = MultinomialNB(alpha=1).fit(Xbl_train, ybl_train)

yl_pred = ideal_multinomial.predict(Xbl_test)

print("Confusion Matrix")
print(confusion_matrix(ybl_test, yl_pred))
print()
print(classification_report(ybl_test, yl_pred))
print()""")


get_ipython().run_cell_magic("time", "", """
param_grid = {
    "criterion": ["gini", "entropy"],
    "min_samples_split": [2, 4, 0.5],
    "max_features": ["sqrt", "log2"]
}

dt_grid = GridSearchCV(DecisionTreeClassifier(), param_grid, n_jobs=-1, verbose=1).fit(Xbs_train, ybs_train)

print("Binary")
print(f"Best Score: {dt_grid.best_score_}")
print(f"Optimal Values: {dt_grid.best_params_}")

dt_grid = GridSearchCV(DecisionTreeClassifier(), param_grid, n_jobs=-1, verbose=1).fit(Xcs_train, ycs_train)

print("Count")
print(f"Best Score: {dt_grid.best_score_}")
print(f"Optimal Values: {dt_grid.best_params_}")""")


get_ipython().run_cell_magic("time", "", """
param_grid = {
    "criterion": ["gini", "entropy"],
    "min_samples_split": [2, 4, 0.5],
    "max_features": ["sqrt", "log2"]
}

dt_grid = GridSearchCV(DecisionTreeClassifier(), param_grid, n_jobs=-1, verbose=1).fit(Xbl_train, ybl_train)

print("Binary")
print(f"Best Score: {dt_grid.best_score_}")
print(f"Optimal Values: {dt_grid.best_params_}")

dt_grid = GridSearchCV(DecisionTreeClassifier(), param_grid, n_jobs=-1, verbose=1).fit(Xcl_train, ycl_train)

print("Count")
print(f"Best Score: {dt_grid.best_score_}")
print(f"Optimal Values: {dt_grid.best_params_}")""")


get_ipython().run_cell_magic("time", "", """
ideal_rf = RandomForestClassifier(n_jobs=-1).fit(Xbs_train, ybs_train)

yb_pred = ideal_rf.predict(Xbs_test)

print("Confusion Matrix")
print(confusion_matrix(ybs_test, ys_pred))
print()
print(classification_report(ybs_test, ys_pred))
print()""")


get_ipython().run_cell_magic("time", "", """
ideal_rf = RandomForestClassifier(n_jobs=-1).fit(Xbl_train, ybl_train)

yl_pred = ideal_rf.predict(Xbl_test)

print("Confusion Matrix")
print(confusion_matrix(ybl_test, yl_pred))
print()
print(classification_report(ybl_test, yl_pred))
print()""")



# With a Lemmatized Text
ideal_pipeline = Pipeline([
    ("vect", CountVectorizer(ngram_range=(1, 2), binary=True)),
    ("clf", MultinomialNB(alpha=1))
])
