import pandas as pd
import seaborn as sns
import matplotlib.pyplot as plt
plt.style.use("ggplot")
from sklearn.model_selection import (train_test_split, 
                                     GridSearchCV, 
                                     cross_val_score)
from sklearn.metrics import (classification_report, 
                             confusion_matrix, 
                             ConfusionMatrixDisplay)
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import RidgeClassifier


df = pd.read_csv("star_classification.csv")


df = df.rename(columns={
    "u": "u'",
    "g": "g'",
    "r": "r'",
    "i": "i'",
    "z": "z'"
})
df.head(5)


sns.catplot(x="class", kind="count", data=df)
plt.title("Distribution of Objects")
plt.xlabel("Type of Object")


sns.catplot(x="class", y="redshift", data=df)
plt.title("Redshift per Class")


plt.figure(figsize=(18, 9))
sns.scatterplot(x="alpha", y="delta", hue="class", data=df)
plt.title("Location of Object in the Night Sky")


df = df.drop(columns=[
    "run_ID",
    "rerun_ID",
    "obj_ID",
    "cam_col",
    "field_ID",
    "plate",
    "fiber_ID",
    "spec_obj_ID"
])
df.head(5)


df["blueshift"] = df["redshift"].map(lambda r: -r)
df.head(5)


X = df.drop(columns=["class"])
y = df["class"]
X_train, X_test, y_train, y_test = train_test_split(X, y)


get_ipython().run_cell_magic("time", "", """
param_grid = {
    "criterion": ["gini", "entropy"],
    "min_samples_split": [2, 4, 6],
    "max_features": ["sqrt", "log2", None]
}

dt_grid = (GridSearchCV(DecisionTreeClassifier(), 
                        param_grid, 
                        n_jobs=-1)
               .fit(X_train, 
                    y_train)
              )

print("Best Score")
print(dt_grid.best_score_)
print()
print("Best Params")
for name, val in dt_grid.best_params_.items():
    print(f"    {name} = {val}")
print()""")


get_ipython().run_cell_magic("time", "", """
random_forest_classifier = RandomForestClassifier(
    criterion="entropy", 
    max_features=None, 
    min_samples_split=6,
    n_jobs=-1
)

random_forest_classifier.fit(X_train, y_train)
print()""")


labels = ["GALAXY", "QSO", "STAR"]
y_pred = random_forest_classifier.predict(X_test)

ConfusionMatrixDisplay(
    confusion_matrix(y_test, y_pred), 
    display_labels=labels
).plot()
plt.title("Random Forest Confusion Matrix")
plt.show()
print()
print("Classification Report")
print(classification_report(y_test, y_pred, target_names=labels))
print()
print("Cross Validation Score")
for idx, score in enumerate(cross_val_score(random_forest_classifier, X, y, n_jobs=-1), 1):
    print(f"        Split {idx} = {score}")


get_ipython().run_cell_magic("time", "", """
param_grid = {
    "n_neighbors": [1,2,3,4,5,6,7,8,9],
    "weights": ["uniform", "distance"],
    "metric": ["minkowski", "manhattan", "chebyshev"],
    "p": [2, 3, 4]
}

kn_grid = GridSearchCV(
    KNeighborsClassifier(), 
    param_grid, 
    n_jobs=-1
).fit(X_train, y_train)

print("Best Score")
print(kn_grid.best_score_)
print()
print("Best Params")
for name, val in kn_grid.best_params_.items():
    print(f"    {name} = {val}")
print()""")


get_ipython().run_cell_magic("time", "", """
kneighbors_model = KNeighborsClassifier(
    metric="manhattan", 
    n_neighbors=3, 
    weights="distance"
)

kneighbors_model.fit(X_train, y_train)
print()""")


get_ipython().run_cell_magic("time", "", """
y_pred = kneighbors_model.predict(X_test)

ConfusionMatrixDisplay(
    confusion_matrix(y_test, y_pred), 
    display_labels=labels
).plot()
plt.title("K Neighbors Confusion Matrix")
plt.show()
print()
print("Classification Report")
print(classification_report(y_test, y_pred, target_names=labels))
print()
print("Cross Validation Score")
for idx, score in enumerate(cross_val_score(kneighbors_model, X, y, n_jobs=-1), 1):
    print(f"        Split {idx} = {score}")
print()""")


get_ipython().run_cell_magic("time", "", """
param_grid = {
    "alpha": [1, 1.5, 1.8, 2],
    "tol": [0.00001, 0.0001, 0.001, 0.01, 0.1],
    "solver": ["svd", "cholesky", "lsqr", "sparse_cg"]
}

rc_grid = GridSearchCV(
    RidgeClassifier(), 
    param_grid, 
    n_jobs=-1
).fit(X_train, y_train)


print("Best Score")
print(rc_grid.best_score_)
print()
print("Best Params")
for name, val in rc_grid.best_params_.items():
    print(f"    {name} = {val}")
print()""")


get_ipython().run_cell_magic("time", "", """
ridge_classifier = RidgeClassifier(
    solver="sparse_cg", 
    alpha=2, 
    tol=0.0001
)

ridge_classifier.fit(X_train, y_train)
print()""")


get_ipython().run_cell_magic("time", "", """
y_pred = ridge_classifier.predict(X_test)

ConfusionMatrixDisplay(
    confusion_matrix(y_test, y_pred), 
    display_labels=labels
).plot()
plt.title("Ridge Classifier Confusion Matrix")
plt.show()
print()
print("Classification Report")
print(classification_report(y_test, y_pred, target_names=labels))
print()
print("Cross Validation Score")
for idx, score in enumerate(cross_val_score(
    ridge_classifier, 
    X, y, n_jobs=-1
), 1):
    print(f"        Split {idx} = {score}")
print()
""")
