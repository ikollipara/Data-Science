import pandas
from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer
from nltk.stem import WordNetLemmatizer
from sklearn.model_selection import train_test_split, GridSearchCV

import matplotlib.pyplot as plt
from wordcloud import WordCloud

from sklearn.naive_bayes import GaussianNB, MultinomialNB, BernoulliNB

from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score, classification_report





hrv_password = ""


import pymysql.cursors

db = pymysql.connect(host = 'cse.unl.edu',
                     user = 'humanrights',
                     password = hrv_password,
                     database = 'humanrights')

cursor = db.cursor()

cursor.execute()


df = pandas.read_sql("""SELECT sentence, hand_label FROM PoliceSentences WHERE hand_label IS NOT NULL""",
                    db)


sentences = df['sentence']
y = df['hand_label']



lemmatizer = WordNetLemmatizer()
analyzer = CountVectorizer().build_analyzer()
def process_word(word):

    word = lemmatizer.lemmatize(word)
    
    return word

# An extensive list of stop words obtained from a union of several lists.
stop_words = eval(open('stop_words.txt').read())

# Additional stop words for the context of Indian HRV
stop_words.extend(["india", "delhi", "singh"])

stop_words = [process_word(word) for word in stop_words]

def process_sentence(sentence):        
    sentence = (process_word(w) for w in analyzer(sentence) if len(w) > 3)
    return (w for w in sentence if (w not in stop_words) and (w[0] not in "0123456789"))

binary_vectorizer = CountVectorizer(strip_accents = 'ascii', analyzer = process_sentence, binary = True)
count_vectorizer = CountVectorizer(strip_accents = 'ascii', analyzer = process_sentence)
tfidf_vectorizer = TfidfVectorizer(strip_accents='ascii', analyzer = process_sentence)


X_binary = binary_vectorizer.fit_transform(sentences)
X_tfidf = tfidf_vectorizer.fit_transform(sentences)
X_count = count_vectorizer.fit_transform(sentences)



 # Start with one review:
text = " ".join(" ".join(process_sentence(sentence)) for sentence in df[df['hand_label'] == 1]['sentence'])

# Create and generate a word cloud image:
wordcloud = WordCloud().generate(text)

# Display the generated image:
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()


 # Start with one review:
text = " ".join(" ".join(process_sentence(sentence)) for sentence in df[df['hand_label'] == 0]['sentence'])

# Create and generate a word cloud image:
wordcloud = WordCloud().generate(text)

# Display the generated image:
plt.imshow(wordcloud, interpolation='bilinear')
plt.axis("off")
plt.show()





Xb_train, Xb_test, yb_train, yb_test = train_test_split(X_binary, y, test_size = 0.2)
Xt_train, Xt_test, yt_train, yt_test = train_test_split(X_tfidf, y, test_size = 0.2)
Xc_train, Xc_test, yc_train, yc_test = train_test_split(X_count, y, test_size = 0.2)


get_ipython().run_cell_magic("time", "", """
param_grid = {'alpha':[0.0001, 0.001, 0.1, 1.0, 1.5, 2.0]}

clf_bernoulli_cv = GridSearchCV(BernoulliNB(), param_grid, cv=5, verbose=1, n_jobs=-1)

clf_bernoulli_cv = clf_bernoulli_cv.fit(Xb_train, yb_train)

print("Best Parameters:", clf_bernoulli_cv.best_params_)
print("Best Score:", clf_bernoulli_cv.best_score_)""")


get_ipython().run_cell_magic("time", "", """bnb = clf_bernoulli_cv.best_estimator_

bnb.fit(Xb_train, yb_train)
""")




yb_pred = bnb.predict(Xb_test)
print("Test - Results from BernoulliNB with Binary CountVectorizer")
print()
print("Test - Confusion Matrix")
print(confusion_matrix(yb_test, yb_pred))
print()
print("Test - Classification Report")
print(classification_report(yb_test, yb_pred))


get_ipython().run_cell_magic("time", "", """
features = Xc_train
target = yc_train

param_grid = {
    'alpha':[0.0001, 0.001, 0.1, 1.0, 1.5, 2.0]
}

clf_multinomial_cv = GridSearchCV(MultinomialNB(), param_grid, cv=5, verbose=1, n_jobs=-1)

clf_multinomial_cv = clf_multinomial_cv.fit(features, target)

print("Best parameters:",clf_multinomial_cv.best_params_)
print("Best Score:", clf_multinomial_cv.best_score_)
""")


get_ipython().run_cell_magic("time", "", """
mnb = clf_multinomial_cv.best_estimator_
mnb.fit(Xc_train.toarray(), yc_train)""")



ym_pred = mnb.predict(Xc_test)
print("Test - Results from MultinomialNB with CountVectorizer")
print()
print("Test - Confusion Matrix")
print(confusion_matrix(yc_test, ym_pred))
print()
print("Test - Classification Report")
print(classification_report(yc_test, ym_pred))


get_ipython().run_cell_magic("time", "", """
param_grid = {
    'priors':[None, [0.8, 0.2]],
    'var_smoothing':[1e-9, 1e-8, 1e-7]
}

clf_gaussian_cv = GridSearchCV(GaussianNB(), param_grid, cv=5, verbose=1, n_jobs=-1)

clf_gaussian_cv = clf_gaussian_cv.fit(Xc_train.toarray(), yc_train)

print("\nBest parameters:",clf_multinomial_cv.best_params_)
print("\nBest Score:", clf_multinomial_cv.best_score_)

""")


get_ipython().run_cell_magic("time", "", """
gnb = clf_gaussian_cv.best_estimator_

gnb.fit(Xc_train.toarray(), yc_train)""")



yg_pred = gnb.predict(Xc_test.toarray())
print("Test - Results from GaussianNB with CountVectorizer")
print()
print("Test - Confusion Matrix")
print(confusion_matrix(yc_test, yg_pred))
print()
print("Test - Classification Report")
print(classification_report(yc_test, yg_pred))


get_ipython().run_cell_magic("time", "", """
param_grid = {
    'priors':[None, [0.8, 0.2]],
    'var_smoothing':[1e-9, 1e-8, 1e-7]
}

clf_gaussian_cv = GridSearchCV(GaussianNB(), param_grid, cv=5, verbose=1, n_jobs=-1)

clf_gaussian_cv = clf_gaussian_cv.fit(Xt_train.toarray(), yt_train)

print("\nBest parameters:",clf_multinomial_cv.best_params_)
print("\nBest Score:", clf_multinomial_cv.best_score_)

""")



yg_pred = gnb.predict(Xt_test.toarray())
print("Test - Results from GaussianNB with TfidfVectorizer")
print()
print("Test - Confusion Matrix")
print(confusion_matrix(yt_test, yg_pred))
print()
print("Test - Classification Report")
print(classification_report(yt_test, yg_pred))


bnb_proba = bnb.predict_proba(Xb_test)
bnb_scores = bnb_proba[:,1]
mnb_proba = mnb.predict_proba(Xc_test)
mnb_scores = mnb_proba[:,1]


from sklearn.metrics import roc_curve, roc_auc_score
from scikitplot.metrics import plot_roc_curve



plot_roc_curve(yb_test, bnb_proba)


plot_roc_curve(yc_test, mnb_proba)


print("Bernoulli Naive Bayes: AUC =", roc_auc_score(yb_test, bnb_scores))
print("Multinomial Naive Bayes: AUC =", roc_auc_score(yc_test, mnb_scores))


from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier()
dt.fit(Xb_train, yb_train)


dt_pred = dt.predict(Xb_test)
print("Test - Results from Decision Tree with Binary Vectorizer")
print()
print("Test - Confusion Matrix")
print(confusion_matrix(yb_test, dt_pred))
print()
print("Test - Classification Report")
print(classification_report(yb_test, dt_pred))


dt_proba = dt.predict_proba(Xb_test)
dt_scores = dt_proba[:,1]


#plot_roc_curve(yb_test, dt_proba)



