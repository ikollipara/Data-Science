import pandas as pd
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier


df = pd.read_csv("Red Wine.csv", sep=";")


quality_dist_plot = sns.histplot(df, x="quality", discrete=True)
quality_dist_plot.set_title("Distribution of Wine Quality Ratings")


q_vs_va_plot = sns.regplot(x="quality", y="volatile acidity", data=df)
q_vs_va_plot.set_title("Quality vs. Volatile Acidity")


df["bound sulfur dioxide"] = df["total sulfur dioxide"] - df["free sulfur dioxide"]


df["quality"] = df["quality"].apply(lambda q: 0 if q < 5 else 1)


# This code is adapted from https://blackboard.cune.edu/bbcswebdav/pid-1545189-dt-content-rid-14535247_1/courses/CS-392-01_202220/ClassificationTutorial.html
X = df.drop("quality", axis=1)
y = df["quality"]
X_train, X_test, y_train, y_test = train_test_split(X, y)


for i in range(3, 8):
    kmodel = KNeighborsClassifier(i)
    kmodel.fit(X_train, y_train)
    
    y_pred = kmodel.predict(X_test)
    print(f"K={i}")
    print(confusion_matrix(y_test, y_pred))
    print()


kmodel = KNeighborsClassifier().fit(X_train, y_train)
y_pred = kmodel.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision = precision_score(y_test, y_pred)
recall = recall_score(y_test, y_pred)
f1_score_ = f1_score(y_test, y_pred)

print(f"Accuracy: {accuracy}")
print(f"Precision: {precision}")
print(f"Recall: {recall}")
print(f"F1 Score: {f1_score_}")


for i in range(4, 11):
    print(f"cv={i}")
    print(cross_val_score(kmodel, X, y, cv=i))
    print()


for i in range(1, 11):
    dt_model = DecisionTreeClassifier(max_depth=i)
    dt_model.fit(X_train, y_train)
    y_pred = dt_model.predict(X_test)
    print(f"max_depth={i}")
    print(confusion_matrix(y_test, y_pred))
    print()


dt_model = DecisionTreeClassifier(max_depth=5).fit(X_train, y_train)
y_pred = dt_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision1 = precision_score(y_test, y_pred)
recall1 = recall_score(y_test, y_pred)
f1_score1 = f1_score(y_test, y_pred)

precision0 = precision_score(y_test, y_pred, pos_label=0)
recall0 = recall_score(y_test, y_pred, pos_label=0)
f1_score0 = f1_score(y_test, y_pred, pos_label=0)

print(f"Accuracy: {accuracy}")
print("Metrics for Class = 1 (Good)")
print(f"    Precision: {precision1}")
print(f"    Recall: {recall1}")
print(f"    F1-Score: {f1_score1}")
print("----------------------------")
print("Metrics for Class = 0 (Bad)")
print(f"    Precision: {precision0}")
print(f"    Recall: {recall0}")
print(f"    F0-Score: {f1_score0}")
print()

for i in range(4, 11):
    print(f"cv={i}")
    print(cross_val_score(dt_model, X, y, cv=i))
    print()


for i in range(1, 11):
    rf_model = RandomForestClassifier(max_depth=i)
    rf_model.fit(X_train, y_train)
    y_pred = rf_model.predict(X_test)
    print(f"max_depth={i}")
    print(confusion_matrix(y_test, y_pred))
    print()


rf_model = RandomForestClassifier(max_depth=8).fit(X_train, y_train)
y_pred = rf_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
precision1 = precision_score(y_test, y_pred)
recall1 = recall_score(y_test, y_pred)
f1_score1 = f1_score(y_test, y_pred)

precision0 = precision_score(y_test, y_pred, pos_label=0, zero_division=1)
recall0 = recall_score(y_test, y_pred, pos_label=0)
f1_score0 = f1_score(y_test, y_pred, pos_label=0)

print(f"Accuracy: {accuracy}")
print("Metrics for Class = 1 (Good)")
print(f"    Precision: {precision1}")
print(f"    Recall: {recall1}")
print(f"    F1-Score: {f1_score1}")
print("----------------------------")
print("Metrics for Class = 0 (Bad)")
print(f"    Precision: {precision0}")
print(f"    Recall: {recall0}")
print(f"    F1-Score: {f1_score0}")
print()

for i in range(4, 11):
    print(f"cv={i}")
    print(cross_val_score(rf_model, X, y, cv=i))
    print()
